# main.py

import os
import asyncio
import zipfile
import glob
import shutil
import json        # <-- [ì¶”ê°€] JSON ì €ì¥ì„ ìœ„í•´ ì„í¬íŠ¸
import httpx       # <-- [ì¶”ê°€] ë¹„ë™ê¸° HTTP í´ë¼ì´ì–¸íŠ¸
from pathlib import Path
from dotenv import load_dotenv

# --- 1. ëª¨ë“ˆ ì„í¬íŠ¸ ---
try:
    import ocr_processor
    import api_clients
except ImportError as e:
    print(f"ğŸš¨ [ì¹˜ëª…ì  ì˜¤ë¥˜] ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    print("   'ocr_processor.py'ì™€ 'api_clients.py' íŒŒì¼ì´ 'main.py'ì™€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    exit()

# --- 2. ì„¤ì • ë° í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ---
load_dotenv()
# (api_clients.pyì—ì„œ ì´ë¯¸ í‚¤ë¥¼ ë¡œë“œí–ˆì§€ë§Œ, mainì—ì„œë„ ê²½ë¡œ í™•ì¸ìš©ìœ¼ë¡œ ë¡œë“œ)

# ë™ì‹œì„± ì œì–´ (í•œ ë²ˆì— 5ê°œì˜ í˜ì´ì§€ë§Œ ë™ì‹œì— ì²˜ë¦¬)
# CPU ì½”ì–´ ìˆ˜ë‚˜ API ì œí•œì— ë§ì¶° ì¡°ì ˆí•˜ì„¸ìš”.
SEMAPHORE = asyncio.Semaphore(2)

# --- 3. ê²½ë¡œ ì„¤ì • ---
BASE_DIR = Path(__file__).resolve().parent
INPUT_DIR = BASE_DIR / "01_input_zips"
TEMP_DIR = BASE_DIR / "02_temp_images"
OUTPUT_DIR = BASE_DIR / "03_output_results"

# --- 4. 0ë‹¨ê³„: ZIP ì••ì¶• í•´ì œ ë° íŒŒì¼ ì¤€ë¹„ ---
def setup_directories_and_unzip():
    print("--- 0ë‹¨ê³„: í´ë” ì„¤ì • ë° ZIP ì••ì¶• í•´ì œ ì‹œì‘ ---")
    INPUT_DIR.mkdir(exist_ok=True)
    TEMP_DIR.mkdir(exist_ok=True)
    OUTPUT_DIR.mkdir(exist_ok=True)

    zip_files = list(INPUT_DIR.glob("*.zip"))
    
    if not zip_files:
        print(f"  [ì•Œë¦¼] {INPUT_DIR} í´ë”ì— ì²˜ë¦¬í•  .zip íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return [], {} # ë¹ˆ ë¦¬ìŠ¤íŠ¸ì™€ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜

    print(f"  [ë°œê²¬] {len(zip_files)}ê°œì˜ ZIP íŒŒì¼ ë°œê²¬.")
    
    all_image_paths = []
    # [ì¶”ê°€] ì›ë³¸ zip(ë§¤ê±°ì§„)ë³„ë¡œ ê²°ê³¼ë¬¼ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ë”•ì…”ë„ˆë¦¬
    # { 'magazine_A': [img1_path, img2_path], 'magazine_B': [img3_path] }
    magazine_map = {}

    for zip_path in zip_files:
        magazine_name = zip_path.stem 
        unzip_target_dir = TEMP_DIR / magazine_name
        unzip_target_dir.mkdir(exist_ok=True)
        print(f"  -> '{zip_path.name}' ì••ì¶• í•´ì œ ì¤‘... -> {unzip_target_dir}")
        
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(unzip_target_dir)
            
            image_extensions = ["*.jpg", "*.jpeg", "*.png"]
            images_in_this_zip = []
            for ext in image_extensions:
                images_in_this_zip.extend(unzip_target_dir.rglob(ext))
            
            images_in_this_zip.sort() # í˜ì´ì§€ ìˆœì„œ ì •ë ¬
            
            print(f"     ... {len(images_in_this_zip)}ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬.")
            all_image_paths.extend(images_in_this_zip)
            # [ì¶”ê°€] ë§¤ê±°ì§„ ë§µì— ì¶”ê°€
            magazine_map[magazine_name] = images_in_this_zip

        except Exception as e:
            print(f"  ğŸš¨ [ì˜¤ë¥˜] '{zip_path.name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    print(f"--- 0ë‹¨ê³„ ì™„ë£Œ: ì´ {len(all_image_paths)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. ---\n")
    return all_image_paths, magazine_map


# --- 5. [ìˆ˜ì •] ë¹„ë™ê¸° íŒŒì´í”„ë¼ì¸ (ì™„ì„±) ---
async def process_page(session: httpx.AsyncClient, image_path: Path):
    """
    ë‹¨ì¼ ì´ë¯¸ì§€ í˜ì´ì§€ íŒŒì´í”„ë¼ì¸ (PaddleOCR -> Azure ë²ˆì—­)
    [ìˆ˜ì •] Gemini ê²€ì¦ ë‹¨ê³„ê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. // ë‚˜ì¤‘ì— ë” ì¢‹ì€ ë°©ë²•ì„ ì°¾ì•„ë³¼ ì˜ˆì •
    """
    
    # [ìˆ˜ì •] Semaphore ê°’ì„ ë‹¤ì‹œ 5 (ë˜ëŠ” ê·¸ ì´ìƒ)ë¡œ ëŒë ¤ë„ ë©ë‹ˆë‹¤.
    # GPUê°€ ë³‘ëª©ì´ë¯€ë¡œ CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° 2~4 ì •ë„ë¡œ í…ŒìŠ¤íŠ¸í•´ ë³´ì„¸ìš”.
    async with SEMAPHORE: # ğŸ‘ˆ main.py ìƒë‹¨ì˜ ì´ ê°’ì„ 4 ì •ë„ë¡œ ìˆ˜ì •í•˜ì„¸ìš”
        print(f"[OCR ì‹œì‘] {image_path.name}")
        
        # --- 1ë‹¨ê³„: OCR (PaddleOCR, ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰) ---
        try:
            structured_data = await asyncio.to_thread(
                ocr_processor.extract_structured_data, 
                image_path
            )
        except Exception as e:
            print(f"ğŸš¨ [OCR ì˜¤ë¥˜] {image_path.name} ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {e}")
            return (image_path, [])

        if not structured_data:
            print(f"[OCR ì™„ë£Œ] {image_path.name}: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¸”ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
            return (image_path, [])
        
        print(f"[OCR ì™„ë£Œ] {image_path.name}: {len(structured_data)}ê°œì˜ í…ìŠ¤íŠ¸ ë¸”ë¡ ë°œê²¬.")
        
        processed_blocks_output = [] # ìµœì¢… ê²°ê³¼(ë²ˆì—­ëœ ë¸”ë¡)ë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸

        # --- [ìˆ˜ì •] 2ë‹¨ê³„: ë²ˆì—­ (Gemini ì—†ì´ ë°”ë¡œ ë²ˆì—­) ---
        
        for i, block in enumerate(structured_data):
            original_text = block['text']
            box = block['box']
            
            if not original_text.strip():
                continue
            
            print(f"  -> {image_path.name} [ë¸”ë¡ {i+1}/{len(structured_data)}] ë²ˆì—­ ì¤‘...")
            
            # [ì œê±°] 1.5. Gemini ê²€ì¦ (ì‚­ì œë¨)
            
            # 2. Azure ë²ˆì—­ (ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë°”ë¡œ ë²ˆì—­)
            translated_text = await api_clients.call_azure_translation(session, original_text)
            
            # [ì œê±°] Gemini 31ì´ˆ ëŒ€ê¸° (ì‚­ì œë¨)
            
            # [ìœ ì§€] Azure ì†ë„ ì œí•œ (0.5ì´ˆ ë˜ëŠ” 1ì´ˆ ëŒ€ê¸°)
            # (PaddleOCRì´ Tesseractë³´ë‹¤ ë¸”ë¡ì„ í›¨ì”¬ ì˜ ë¬¶ì–´ì£¼ë¯€ë¡œ
            # í˜¸ì¶œ íšŸìˆ˜ê°€ ì¤„ì–´, ì´ ëŒ€ê¸° ì‹œê°„ë„ 0.2ì´ˆ ë“±ìœ¼ë¡œ ì¤„ì—¬ë„ ë©ë‹ˆë‹¤.)
            await asyncio.sleep(0.5) 

            # 3. ê²°ê³¼ ì €ì¥
            processed_blocks_output.append({
                'box': box,
                'original_text': original_text,
                'clean_text': original_text, # ì›ë³¸ = ê¹¨ë—í•œ í…ìŠ¤íŠ¸
                'translated_text': translated_text
            })

        print(f"âœ… [ì²˜ë¦¬ ì™„ë£Œ] {image_path.name}")
        return (image_path, processed_blocks_output)
    
# --- 6. [ì‹ ê·œ] 3ë‹¨ê³„: ê²°ê³¼ ì €ì¥ ---

def save_results(magazine_map: dict, all_page_results: list):
    """
    ëª¨ë“  ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë§¤ê±°ì§„ë³„ JSON íŒŒì¼ë¡œ 03_output_resultsì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    print("\n--- 3ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ì €ì¥ ì‹œì‘ ---")
    
    # (ì´ë¯¸ì§€ ê²½ë¡œ, ë¸”ë¡ ë¦¬ìŠ¤íŠ¸) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ë¹ ë¥¸ ì¡°íšŒìš©)
    # { 'img1_path': [...], 'img2_path': [...] }
    results_dict = dict(all_page_results)
    
    for magazine_name, image_paths in magazine_map.items():
        # ì´ ë§¤ê±°ì§„ì˜ ìµœì¢… JSON êµ¬ì¡°
        output_data = {
            'magazine_name': magazine_name,
            'total_pages': len(image_paths),
            'pages': []
        }
        
        print(f"  -> '{magazine_name}' ê²°ê³¼ ì·¨í•© ì¤‘...")
        
        # ì •ë ¬ëœ ì´ë¯¸ì§€ ê²½ë¡œ(í˜ì´ì§€ ìˆœì„œ)ë¥¼ ìˆœíšŒ
        for i, img_path in enumerate(image_paths):
            page_data = {
                'page_number': i + 1,
                'original_filename': img_path.name,
                'blocks': results_dict.get(img_path, []) # process_page ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            }
            output_data['pages'].append(page_data)
            
        # ë§¤ê±°ì§„ë³„ë¡œ í•˜ë‚˜ì˜ JSON íŒŒì¼ ìƒì„±
        output_filename = OUTPUT_DIR / f"{magazine_name}_translated.json"
        
        try:
            with open(output_filename, 'w', encoding='utf-8') as f:
                # ensure_ascii=Falseë¡œ í•œê¸€ì´ ê¹¨ì§€ì§€ ì•Šê²Œ ì €ì¥
                # indent=2ë¡œ ê°€ë…ì„± ë†’ê²Œ ì €ì¥
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            print(f"  âœ… [ì €ì¥ ì„±ê³µ] {output_filename}")
        except Exception as e:
            print(f"  ğŸš¨ [ì €ì¥ ì˜¤ë¥˜] {output_filename} ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    print("--- 3ë‹¨ê³„ ì™„ë£Œ ---")


# --- 7. 4ë‹¨ê³„: ì„ì‹œ íŒŒì¼ ì •ë¦¬ ---
def cleanup_temp_files():
    print(f"\n--- 4ë‹¨ê³„: ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹œì‘ ---")
    if not TEMP_DIR.exists():
        return
    try:
        shutil.rmtree(TEMP_DIR)
        print(f"  âœ… [ì„±ê³µ] {TEMP_DIR} í´ë”ì™€ ëª¨ë“  í•˜ìœ„ íŒŒì¼ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        TEMP_DIR.mkdir(exist_ok=True)
    except OSError as e:
        print(f"  ğŸš¨ [ì˜¤ë¥˜] {TEMP_DIR} í´ë” ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# --- 8. [ìˆ˜ì •] ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°) ---

async def main():
    """ë©”ì¸ ë¹„ë™ê¸° ì‹¤í–‰ í•¨ìˆ˜ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°)"""
    
    image_paths_to_process = []
    magazine_map = {}
    all_page_results = []

    try:
        # 0ë‹¨ê³„: í´ë” ì¤€ë¹„ ë° ì••ì¶• í•´ì œ
        image_paths_to_process, magazine_map = setup_directories_and_unzip()
        
        if not image_paths_to_process:
            print("ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return

        print(f"\n--- 1/2ë‹¨ê³„: OCR, ê²€ì¦, ë²ˆì—­ ì‘ì—… ë™ì‹œ ì‹œì‘ (ì´ {len(image_paths_to_process)}ê°œ) ---")

        # httpx.AsyncClient ì„¸ì…˜ì„ ìƒì„±í•˜ì—¬ ì»¤ë„¥ì…˜ í’€ì„ ì¬ì‚¬ìš© (ì†ë„ í–¥ìƒ)
        async with httpx.AsyncClient(timeout=30.0) as session:
            # ë¹„ë™ê¸° ì‘ì—… ëª©ë¡ ìƒì„±
            tasks = []
            for img_path in image_paths_to_process:
                tasks.append(process_page(session, img_path))
            
            # asyncio.gatherë¥¼ ì‚¬ìš©í•´ ëª¨ë“  ì‘ì—…ì„ "ë™ì‹œì—" (ìµœëŒ€ 5ê°œì”©) ì‹¤í–‰
            # all_page_results: [(img_path, [block_data, ...]), ...]
            all_page_results = await asyncio.gather(*tasks)

        print("\n--- ëª¨ë“  í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ ---")
        
        # 3ë‹¨ê³„: ê²°ê³¼ íŒŒì¼ë¡œ ì €ì¥
        if magazine_map and all_page_results:
            save_results(magazine_map, all_page_results)
        else:
            print("[ì•Œë¦¼] ì²˜ë¦¬ëœ ê²°ê³¼ê°€ ì—†ì–´ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")


    except Exception as e:
        print(f"ğŸš¨ [ì¹˜ëª…ì  ì˜¤ë¥˜] ë©”ì¸ ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    finally:
        # 4ë‹¨ê³„: ì„ì‹œ íŒŒì¼ ì •ë¦¬
        cleanup_temp_files()


if __name__ == "__main__":
    print("=========================================")
    print("   ë§¤ê±°ì§„ ë²ˆì—­ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘")
    print("=========================================\n")
    asyncio.run(main())
    print("\n=========================================")
    print("   ëª¨ë“  ì‘ì—… ì™„ë£Œ. ìŠ¤í¬ë¦½íŠ¸ ì¢…ë£Œ.")
    print("=========================================")